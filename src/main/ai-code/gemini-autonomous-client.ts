/**
 * Autonomous Gemini AI Client Service
 * Implements streaming conversation loops with tool execution
 * Based on Gemini CLI patterns adapted for EGDesk
 */

import { GoogleGenerativeAI, GenerationConfig, Content, Part, FunctionCall, Tool } from '@google/generative-ai';
import { ipcMain } from 'electron';
const { v4: uuidv4 } = require('uuid');
import { toolRegistry } from './tool-executor';
import { loopDetectionService } from './loop-detection';
import { projectContextBridge } from './project-context-bridge';
import { getEGDeskSystemPrompt } from './prompts/system-prompt';
import { getSQLiteManager } from '../sqlite/manager';
import { AIChatDatabase, conversationMessageToAIMessage } from '../sqlite/ai';
import type { 
  AIClientConfig, 
  ConversationMessage, 
  AIResponse, 
  AIClientService,
  AIStreamEvent,
  ToolCallRequestInfo,
  ToolCallResponseInfo,
  ConversationState,
  ConversationTurn,
  ToolDefinition
} from '../types/ai-types';
import { AIEventType } from '../types/ai-types';

export class AutonomousGeminiClient implements AIClientService {
  private genAI?: GoogleGenerativeAI;
  private model?: any;
  private config?: AIClientConfig;
  private conversationHistory: ConversationMessage[] = [];
  private conversationState: ConversationState | null = null;
  private abortController?: AbortController;
  
  // Event buffering for conversations
  private conversationEventBuffers = new Map<string, AIStreamEvent[]>();
  private conversationSenders = new Map<string, Electron.WebContents>();
  
  // SQLite integration
  private sqliteManager = getSQLiteManager();
  private aiChatDb?: AIChatDatabase;
  private currentConversationId?: string;

  constructor() {
    this.initializeSQLite();
    this.registerIPCHandlers();
  }

  /**
   * Initialize SQLite database for AI chat storage
   */
  private async initializeSQLite(): Promise<void> {
    try {
      const result = await this.sqliteManager.initialize();
      if (result.success) {
        this.aiChatDb = new AIChatDatabase(this.sqliteManager.getDatabase());
        console.log('‚úÖ SQLite database initialized for AI chat storage');
      } else {
        console.error('‚ùå Failed to initialize SQLite for AI chat:', result.error);
      }
    } catch (error) {
      console.error('‚ùå Error initializing SQLite for AI chat:', error);
    }
  }

  /**
   * Configure the Gemini client
   */
  async configure(config: AIClientConfig): Promise<boolean> {
    try {
      this.genAI = new GoogleGenerativeAI(config.apiKey);
      
      // Get project context for system prompt
      const projectContext = await this.getProjectContext();
      const systemPrompt = getEGDeskSystemPrompt(projectContext || undefined);
      
      this.model = this.genAI.getGenerativeModel({
        model: config.model || 'gemini-2.5-flash',
        generationConfig: {
          temperature: config.temperature || 0.7,
          topP: config.topP || 0.8,
          maxOutputTokens: config.maxOutputTokens || 4096,
        },
        systemInstruction: systemPrompt
      });

      this.config = config;
      console.log('‚úÖ Autonomous Gemini client configured with EGDesk system prompt');
      return true;
    } catch (error) {
      console.error('‚ùå Failed to configure Gemini client:', error);
      return false;
    }
  }

  /**
   * Check if client is configured
   */
  isConfigured(): boolean {
    return !!(this.genAI && this.model && this.config);
  }


  /**
   * NEW: Autonomous streaming conversation with tool execution
   */
  async *sendMessageStream(
    message: string, 
    options: {
      tools?: ToolDefinition[];
      maxTurns?: number;
      timeoutMs?: number;
      autoExecuteTools?: boolean;
      context?: Record<string, any>;
    } = {}
  ): AsyncGenerator<AIStreamEvent> {
    if (!this.isConfigured()) {
      yield {
        type: AIEventType.Error,
        error: { message: 'AI client not configured', recoverable: false },
        timestamp: new Date()
      };
      return;
    }

    // Initialize conversation state
    const sessionId = uuidv4();
    this.conversationState = {
      sessionId,
      turns: [],
      currentTurn: 0,
      isActive: true,
      maxTurns: options.maxTurns || 20,
      timeoutMs: options.timeoutMs || 300000, // 5 minutes
      startTime: new Date(),
      context: options.context
    };

    // Create conversation in SQLite
    this.currentConversationId = sessionId;
    await this.createConversationInSQLite(sessionId, message, options.context);

    // Setup abort controller for cancellation
    this.abortController = new AbortController();
    const timeoutId = setTimeout(() => {
      this.abortController?.abort();
    }, this.conversationState.timeoutMs);

    // Reset loop detection
    loopDetectionService.reset();

    try {
      console.log('üõ†Ô∏è Getting available tools...');
      // Get available tools
      const availableTools = options.tools || toolRegistry.getToolDefinitions();
      console.log('üìã Available tools:', availableTools.map(t => t.name));
      
      const geminiTools: Tool[] = this.convertToolsForGemini(availableTools);
      const totalFunctions = geminiTools.reduce((sum, tool) => sum + ((tool as any).functionDeclarations?.length || 0), 0);
      console.log('üîß Converted tools for Gemini:', `${geminiTools.length} tool objects containing ${totalFunctions} functions`);

      // Start conversation loop
      console.log('üöÄ Starting conversation loop...');
      yield* this.conversationLoop(message, geminiTools, options.autoExecuteTools || true);

    } catch (error) {
      yield {
        type: AIEventType.Error,
        error: { 
          message: error instanceof Error ? error.message : 'Unknown error',
          recoverable: false 
        },
        timestamp: new Date()
      };
    } finally {
      clearTimeout(timeoutId);
      this.conversationState = null;
      this.abortController = undefined;
    }
  }

  /**
   * Main conversation loop - the heart of autonomous operation
   */
  private async *conversationLoop(
    initialMessage: string, 
    tools: Tool[], 
    autoExecuteTools: boolean
  ): AsyncGenerator<AIStreamEvent> {
    console.log('üîÑ Starting conversation loop with message:', initialMessage);
    console.log('üõ†Ô∏è Available tools:', tools.length);
    console.log('tools:', tools);
    
    let currentMessage = initialMessage;
    let turnNumber = 0;

    // Add initial user message to history
    this.addToHistory({
      role: 'user',
      parts: [{ text: currentMessage }],
      timestamp: new Date()
    });

    while (this.conversationState?.isActive && turnNumber < this.conversationState.maxTurns) {
      if (this.abortController?.signal.aborted) {
        yield {
          type: AIEventType.UserCancelled,
          timestamp: new Date()
        } as any;
        break;
      }

      turnNumber++;
      yield {
        type: AIEventType.TurnStarted,
        turnNumber,
        timestamp: new Date()
      };

      // Create new turn
      const turn: ConversationTurn = {
        turnNumber,
        toolCalls: [],
        toolResponses: [],
        startTime: new Date(),
        status: 'active'
      };

      this.conversationState.turns.push(turn);
      this.conversationState.currentTurn = turnNumber;

      try {
        // Prefix the user message with a concise route hint if available
        console.log('üîç Using route hint when available to provide current path/url context');
        const routeHint = this.buildRouteHint();
        let contextualMessage = routeHint ? `${routeHint}\n\n${currentMessage}` : currentMessage;

        // if image files are in the context, add them to the message
        if (this.conversationState.context?.attachedFiles) {
          contextualMessage = `${contextualMessage}\n\nAttached files: ${this.conversationState.context.attachedFiles.map(f => f.filePath).join(', ')}`;
        }

        // Send message to Gemini with tools
        const result = await this.model!.generateContent({
          contents: [
            ...this.getConversationHistoryForGemini(),
            { role: 'user', parts: [{ text: contextualMessage }] }
          ],
          tools: tools.length > 0 ? tools : undefined
        });

        const response = await result.response;
        const candidates = response.candidates || [];
        
        if (candidates.length === 0) {
          throw new Error('No response candidates from Gemini');
        }

        const candidate = candidates[0];
        const content = candidate.content;

        // Process response content
        if (content?.parts) {
          for (const part of content.parts) {
            // Handle text content
            if (part.text) {
              // Stream the text in chunks for better UX
              yield* this.streamTextContent(part.text);

              // Check for response loops
              if (loopDetectionService.checkResponseLoop(part.text)) {
                yield {
                  type: AIEventType.LoopDetected,
                  pattern: 'Repetitive AI responses detected',
                  timestamp: new Date()
                };
                this.conversationState.isActive = false;
                break;
              }
            }

            // Handle function calls
            if (part.functionCall) {
              const toolCallRequest: ToolCallRequestInfo = {
                id: uuidv4(),
                name: part.functionCall.name || 'unknown',
                parameters: part.functionCall.args || {},
                timestamp: new Date(),
                turnNumber,
                conversationId: this.currentConversationId
              };

              // Check for tool call loops
              if (loopDetectionService.checkToolCallLoop(toolCallRequest)) {
                yield {
                  type: AIEventType.LoopDetected,
                  pattern: 'Repetitive tool calls detected',
                  timestamp: new Date()
                };
                this.conversationState.isActive = false;
                break;
              }

              turn.toolCalls.push(toolCallRequest);

              // Add tool call to conversation history as a model turn with functionCall
              this.addToHistory({
                role: 'model',
                parts: [part],
                timestamp: new Date(),
                toolCallId: toolCallRequest.id,
                toolStatus: 'executing'
              });

              yield {
                type: AIEventType.ToolCallRequest,
                toolCall: toolCallRequest,
                timestamp: new Date()
              };

              // Execute tool if auto-execution is enabled
              if (autoExecuteTools) {
                console.log('üîß Executing tool call:', toolCallRequest.name, 'with params:', toolCallRequest.parameters);
                
                const toolResponse = await toolRegistry.executeToolCall(
                  toolCallRequest, 
                  this.abortController?.signal
                );

                console.log('üîß Tool response:', {
                  success: toolResponse.success,
                  error: toolResponse.error,
                  resultType: typeof toolResponse.result,
                  result: toolResponse.result
                });

                turn.toolResponses.push(toolResponse);

                yield {
                  type: AIEventType.ToolCallResponse,
                  response: toolResponse,
                  timestamp: new Date()
                };

                // Add tool response to conversation history
                this.addToHistory({
                  role: 'model',
                  parts: [part],
                  timestamp: new Date()
                });

                this.addToHistory({
                  role: 'model',
                  parts: [{
                    functionResponse: {
                      name: toolCallRequest.name,
                      response: toolResponse.success 
                        ? (typeof toolResponse.result === 'object' && !Array.isArray(toolResponse.result)
                            ? toolResponse.result  // Already an object, use directly
                            : { result: toolResponse.result })  // Wrap primitives and arrays
                        : { error: toolResponse.error }
                    }
                  }],
                  timestamp: new Date(),
                  toolCallId: toolCallRequest.id,
                  toolStatus: toolResponse.success ? 'completed' : 'failed'
                });

                // Continue conversation with tool result and context
                if (toolResponse.success) {
                  // Provide context-aware continuation message based on the tool and result
                  currentMessage = this.generateContinuationMessage(toolCallRequest.name, toolResponse.result, initialMessage);
                  console.log('üîÑ Generated continuation message:', currentMessage.substring(0, 200) + '...');
                } else {
                  currentMessage = `Tool execution failed: ${toolResponse.error}. Please try a different approach or fix the issue.`;
                  console.log('‚ùå Tool execution failed, generated error message');
                }
              }
            }
          }
        }

        // Mark turn as completed
        turn.endTime = new Date();
        turn.status = 'completed';

        // Save turn data to SQLite
        this.saveTurnToSQLite(turn);

        yield {
          type: AIEventType.TurnCompleted,
          turnNumber,
          timestamp: new Date()
        };

        // Check if conversation should continue
        const shouldContinue = this.shouldContinueConversation(turn, response);
        console.log('üîÑ Conversation continuation check:', {
          shouldContinue,
          toolCallsInTurn: turn.toolCalls.length,
          finishReason: response.candidates?.[0]?.finishReason,
          turnNumber,
          maxTurns: this.conversationState?.maxTurns
        });
        
        if (!shouldContinue) {
          console.log('üèÅ Conversation ending: AI indicated completion');
          yield {
            type: AIEventType.Finished,
            reason: 'tool_calls_complete',
            timestamp: new Date()
          };
          break;
        }

      } catch (error) {
        turn.status = 'error';
        turn.endTime = new Date();

        const isRecoverable = !this.abortController?.signal.aborted;
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        
        console.error('‚ùå Error in conversation turn:', errorMessage);
        console.error('‚ùå Error details:', error);
        
        yield {
          type: AIEventType.Error,
          error: {
            message: errorMessage,
            recoverable: isRecoverable
          },
          timestamp: new Date()
        };

        if (!isRecoverable) break;
      }
    }

    // Conversation ended
    if (this.conversationState) {
      this.conversationState.isActive = false;
    }

    yield {
      type: AIEventType.Finished,
      reason: turnNumber >= (this.conversationState?.maxTurns || 20) ? 'max_turns' : 'tool_calls_complete',
      timestamp: new Date()
    };
  }

  /**
   * Build a one-line route hint for the model from conversation context
   */
  private buildRouteHint(): string | null {
    try {
      const ctx: any = (this.conversationState as any)?.context || {};
      const currentPath = ctx.currentPath as string | undefined;
      const currentUrl = ctx.currentUrl as string | undefined;
      const projectPath = ctx.projectPath as string | undefined;
      if (!currentPath && !currentUrl) return null;
      const parts: string[] = [];
      if (currentPath) parts.push(`route: ${currentPath}`);
      if (currentUrl) parts.push(`url: ${currentUrl}`);
      const suggestedDir = this.deriveSuggestedDir(projectPath, currentPath);
      // Also nudge the model to list directory and read likely files first, with a concrete dirPath
      const dirNudge = suggestedDir ? `Use list_directory with dirPath: ${suggestedDir}. Then read_file likely candidates (e.g., index.php, inc/header.php).` : `First list that route's directory, then open likely files (e.g., index.php or matching templates).`;
      return `Currently viewing (${parts.join(', ')}). ${dirNudge}`;
    } catch {
      return null;
    }
  }

  /**
   * Heuristically derive a filesystem directory for the current route
   */
  private deriveSuggestedDir(projectPath?: string, currentPath?: string): string | null {
    try {
      if (!projectPath) return null;
      const root = projectPath.replace(/\\+/g, '/');
      const pathPart = (currentPath || '/').replace(/\?.*$/, '').replace(/\/+/g, '/');
      // Common PHP site structure: use www as web root when present
      const wwwRoot = `${root}/www`;
      const hasWww = require('fs').existsSync(wwwRoot);
      const base = hasWww ? wwwRoot : root;
      // Handle locale prefix like /en_v1
      const segs = pathPart.split('/').filter(Boolean);
      let rel = '';
      if (segs.length === 0) {
        rel = '';
      } else if (segs[0].match(/^en(_v\d+)?$/) || segs[0].startsWith('en_') || segs[0] === 'en_v1') {
        rel = segs.slice(0, 2).join('/'); // e.g., en_v1 or en_v1/index.php
      } else {
        rel = segs.join('/');
      }
      const candidate = `${base}/${rel}`.replace(/\/+$|\/$/g, '');
      return candidate || base;
    } catch {
      return null;
    }
  }

  /**
   * Generate a context-aware continuation message after tool execution
   */
  private generateContinuationMessage(toolName: string, toolResult: any, originalRequest: string): string {
    switch (toolName) {
      case 'analyze_project':
        return `Project analysis completed. Based on the analysis, the project is a ${toolResult.analysis?.projectType || 'Unknown'} project with ${toolResult.analysis?.totalFiles || 0} files. Now please continue with the original request: "${originalRequest}". Use the project analysis data to inform your next actions.`;
      
      case 'list_directory':
        const fileCount = Array.isArray(toolResult) ? toolResult.length : 0;
        return `Directory listing completed, found ${fileCount} items. Please continue with the original request: "${originalRequest}". Use this directory information to guide your next steps.`;
      
      case 'read_file':
        const contentLength = typeof toolResult === 'string' ? toolResult.length : 0;
        return `File read completed (${contentLength} characters). Please continue with the original request: "${originalRequest}". Use the file content to inform your next actions.`;
      
      case 'write_file':
        return `File write completed successfully. Please continue with the original request: "${originalRequest}". Consider what additional files or documentation might be needed.`;
      
      default:
        return `Tool "${toolName}" execution completed. Result: ${JSON.stringify(toolResult)}. Please continue with the original request: "${originalRequest}".`;
    }
  }

  /**
   * Determine if conversation should continue
   */
  private shouldContinueConversation(turn: ConversationTurn, response: any): boolean {
    // Check finish reason first - if AI explicitly says STOP, respect that
    const finishReason = response.candidates?.[0]?.finishReason;
    if (finishReason === 'STOP') {
      // Only stop if there were no tool calls in this turn (AI is truly done)
      return turn.toolCalls.length > 0;
    }

    // Continue if there were tool calls (AI needs to process results)
    if (turn.toolCalls.length > 0) {
      return true;
    }

    // Check if the AI response contains completion indicators
    const responseText = response.candidates?.[0]?.content?.parts?.[0]?.text || '';
    const completionIndicators = [
      'task completed',
      'documentation created',
      'analysis complete',
      'all files created',
      'project documentation is now complete'
    ];
    
    if (completionIndicators.some(indicator => responseText.toLowerCase().includes(indicator))) {
      return false;
    }

    // Continue for other reasons (SAFETY, LENGTH, etc.) but with limits
    return true;
  }

  /**
   * Stream text content in chunks for better UX
   */
  private async *streamTextContent(text: string): AsyncGenerator<AIStreamEvent> {
    // Split text into words for more natural streaming
    const words = text.split(/(\s+)/);
    let currentChunk = '';
    
    for (let i = 0; i < words.length; i++) {
      const word = words[i];
      currentChunk += word;
      
      // Yield chunk every few words or at punctuation
      const shouldYield = 
        i === words.length - 1 || // Last word
        currentChunk.length > 50 || // Chunk size limit
        /[.!?]\s*$/.test(currentChunk) || // End of sentence
        (i > 0 && i % 3 === 0); // Every 3 words
      
      if (shouldYield) {
        yield {
          type: AIEventType.Content,
          content: currentChunk,
          timestamp: new Date()
        };
        currentChunk = '';
        
        // Small delay between chunks for streaming effect
        if (i < words.length - 1) {
          await new Promise(resolve => setTimeout(resolve, 50));
        }
      }
    }
  }

  /**
   * Convert tool definitions to Gemini format
   */
  private convertToolsForGemini(tools: ToolDefinition[]): Tool[] {
    return [{
      functionDeclarations: tools.map(tool => ({
        name: tool.name,
        description: tool.description,
        parameters: tool.parameters as any // Cast to bypass type issues
      }))
    } as any]; // Cast the whole tool object
  }

  /**
   * Get conversation history in Gemini format
   */
  private getConversationHistoryForGemini(): Content[] {
    return this.conversationHistory.map(msg => ({
      role: msg.role,
      parts: msg.parts
    }));
  }

  /**
   * Get project context for AI
   */
  private async getProjectContext(): Promise<string | null> {
    try {
      // Use the full project context string that includes tool instructions and exploration strategy
      return projectContextBridge.getProjectContextString();
    } catch {
      return null;
    }
  }


  async executeToolCall(request: ToolCallRequestInfo): Promise<ToolCallResponseInfo> {
    return toolRegistry.executeToolCall(request);
  }

  addToHistory(message: ConversationMessage): void {
    this.conversationHistory.push(message);
    
    // Keep history manageable (last 50 messages)
    if (this.conversationHistory.length > 50) {
      this.conversationHistory = this.conversationHistory.slice(-50);
    }
  }

  getHistory(): ConversationMessage[] {
    // Return in-memory history for current session
    return [...this.conversationHistory];
  }

  clearHistory(): void {
    this.conversationHistory = [];
  }

  /**
   * Get conversation history from SQLite
   */
  async getConversationHistory(conversationId: string): Promise<ConversationMessage[]> {
    if (!this.aiChatDb) {
      console.warn('‚ö†Ô∏è AI Chat database not available, returning empty history');
      return [];
    }

    try {
      const messages = this.aiChatDb.getMessages(conversationId);
      return messages.map(msg => ({
        role: msg.role === 'tool' ? 'model' : msg.role as 'user' | 'model',
        parts: [{ text: msg.content }],
        timestamp: new Date(msg.timestamp),
        toolCallId: msg.tool_call_id,
        toolStatus: msg.tool_status
      }));
    } catch (error) {
      console.error('‚ùå Failed to get conversation history from SQLite:', error);
      return [];
    }
  }

  getConversationState(): ConversationState | null {
    return this.conversationState ? { ...this.conversationState } : null;
  }

  cancelConversation(): void {
    if (this.conversationState?.isActive) {
      this.conversationState.isActive = false;
      this.abortController?.abort();
    }
  }

  isConversationActive(): boolean {
    return this.conversationState?.isActive || false;
  }

  getAvailableModels(): string[] {
    return [
      'gemini-2.5-flash',
      'gemini-1.5-flash-latest',
      'gemini-1.5-pro-latest',
      'gemini-1.0-pro'
    ];
  }

  /**
   * Register IPC handlers for renderer communication
   */
  private registerIPCHandlers(): void {
    // Legacy handlers
    ipcMain.handle('ai-configure', async (event, config: AIClientConfig) => {
      return await this.configure(config);
    });

    ipcMain.handle('ai-is-configured', async () => {
      return this.isConfigured();
    });


    // New streaming handlers
    ipcMain.handle('ai-start-autonomous-conversation', async (event, message: string, options: any) => {
      console.log('üéØ IPC: ai-start-autonomous-conversation called with:', message);
      
      // Return a conversation ID for tracking
      const conversationId = uuidv4();
      console.log('üÜî Generated conversation ID:', conversationId);
      
      // Initialize event buffer and store sender for this conversation
      this.conversationEventBuffers.set(conversationId, []);
      this.conversationSenders.set(conversationId, event.sender);
      
      // Start streaming in background with a small delay to allow renderer to register event handlers
      setTimeout(async () => {
        try {
          console.log('üîÑ Starting autonomous conversation stream...');
          for await (const streamEvent of this.sendMessageStream(message, options)) {
            console.log('üì° Buffering stream event:', streamEvent.type);
            this.bufferEvent(conversationId, streamEvent);
          }
          console.log('‚úÖ Autonomous conversation stream completed');
          
          // Clean up conversation resources after completion
          setTimeout(() => {
            this.cleanupConversation(conversationId);
          }, 5000); // Clean up after 5 seconds to allow final events to be processed
        } catch (error) {
          console.error('‚ùå Error in autonomous conversation stream:', error);
          this.bufferEvent(conversationId, {
            type: AIEventType.Error,
            error: { message: error instanceof Error ? error.message : 'Unknown error', recoverable: false },
            timestamp: new Date()
          });
        }
      }, 100); // 100ms delay to allow renderer to register event handlers

      return { conversationId };
    });

    // Add handler for renderer to signal it's ready to receive events
    ipcMain.handle('ai-conversation-ready', async (event, conversationId: string) => {
      console.log('üéØ Renderer ready for conversation:', conversationId);
      console.log('üéØ Event sender:', event.sender);
      
      // Store the sender for immediate event transmission
      this.conversationSenders.set(conversationId, event.sender);
      console.log('üéØ Stored sender for conversation:', conversationId);
      console.log('üéØ Total senders:', this.conversationSenders.size);
      
      // Flush any buffered events
      this.flushEventBuffer(conversationId);
      return true;
    });

    ipcMain.handle('ai-cancel-conversation', async () => {
      this.cancelConversation();
      return true;
    });

    ipcMain.handle('ai-get-conversation-state', async () => {
      return this.getConversationState();
    });

    // History and utility handlers
    ipcMain.handle('ai-get-history', async () => {
      return this.getHistory();
    });

    ipcMain.handle('ai-clear-history', async () => {
      this.clearHistory();
      return true;
    });

    ipcMain.handle('ai-get-models', async () => {
      return this.getAvailableModels();
    });

    // Tool confirmation handlers
    ipcMain.handle('ai-tool-confirm', async (event, requestId: string, approved: boolean) => {
      const result = await toolRegistry.confirmToolExecution(requestId, approved);
      return result;
    });

    ipcMain.handle('ai-get-tool-definitions', async () => {
      return toolRegistry.getToolDefinitions();
    });

    // Simple image send handler: send an image file to Gemini with optional prompt
    ipcMain.handle('ai-send-image', async (event, filePath: string, prompt?: string) => {
      try {
        if (!this.isConfigured()) {
          return { success: false, error: 'AI client not configured' };
        }
        const fs = require('fs');
        const path = require('path');

        if (!filePath || !fs.existsSync(filePath)) {
          return { success: false, error: 'Invalid file path' };
        }

        const buffer = fs.readFileSync(filePath);
        const base64 = buffer.toString('base64');
        const ext = (path.extname(filePath) || '').toLowerCase();
        const mimeMap: Record<string, string> = {
          '.png': 'image/png',
          '.jpg': 'image/jpeg',
          '.jpeg': 'image/jpeg',
          '.gif': 'image/gif',
          '.webp': 'image/webp',
          '.bmp': 'image/bmp',
          '.svg': 'image/svg+xml'
        };
        const mimeType = mimeMap[ext] || 'application/octet-stream';

        const parts: any[] = [];
        if (prompt && prompt.trim()) {
          parts.push({ text: prompt.trim() });
        }
        parts.push({ inlineData: { data: base64, mimeType } });

        const result = await this.model!.generateContent({
          contents: [ { role: 'user', parts } ]
        });
        const text = result?.response?.text ? await result.response.text() : '';
        return { success: true, text };
      } catch (error) {
        return { success: false, error: error instanceof Error ? error.message : 'Unknown error' };
      }
    });

    console.log('‚úÖ Autonomous Gemini AI IPC handlers registered');
  }

  /**
   * Buffer an event for a conversation or send immediately if sender is available
   */
  private bufferEvent(conversationId: string, event: AIStreamEvent): void {
    const buffer = this.conversationEventBuffers.get(conversationId);
    const sender = this.conversationSenders.get(conversationId);
    
    console.log('üì§ BufferEvent called:', {
      conversationId,
      eventType: event.type,
      hasSender: !!sender,
      hasBuffer: !!buffer,
      bufferSize: buffer?.length || 0
    });
    
    if (sender) {
      sender.send('ai-stream-event', conversationId, event);
    } else if (buffer) {
      buffer.push(event);
    } else {
      console.warn('‚ö†Ô∏è No buffer or sender available for conversation:', conversationId);
    }
  }

  /**
   * Flush all buffered events for a conversation
   */
  private flushEventBuffer(conversationId: string): void {
    const buffer = this.conversationEventBuffers.get(conversationId);
    const sender = this.conversationSenders.get(conversationId);
    
    if (buffer && sender && buffer.length > 0) {
      console.log(`üì§ Flushing ${buffer.length} buffered events for conversation:`, conversationId);
      for (const event of buffer) {
        sender.send('ai-stream-event', conversationId, event);
      }
      
      // Clear buffer after flushing (but keep sender for future events)
      this.conversationEventBuffers.set(conversationId, []);
    } else {
      console.log(`üì§ No buffered events to flush for conversation: ${conversationId} (buffer: ${buffer?.length || 0}, sender: ${!!sender})`);
    }
  }

  /**
   * Clean up resources for a specific conversation
   */
  private cleanupConversation(conversationId: string): void {
    console.log('üßπ Cleaning up conversation:', conversationId);
    this.conversationEventBuffers.delete(conversationId);
    this.conversationSenders.delete(conversationId);
  }

  /**
   * Clean up all conversation resources
   */
  private cleanupAllConversations(): void {
    console.log('üßπ Cleaning up all conversations');
    this.conversationEventBuffers.clear();
    this.conversationSenders.clear();
  }

  /**
   * Create conversation in SQLite database
   */
  private async createConversationInSQLite(sessionId: string, initialMessage: string, context?: Record<string, any>): Promise<void> {
    if (!this.aiChatDb) {
      console.warn('‚ö†Ô∏è AI Chat database not available, skipping conversation creation');
      return;
    }

    try {
      const conversationTitle = this.generateConversationTitle(initialMessage);
      const projectContext = context ? JSON.stringify(context) : '{}';
      
      console.log('üîß Creating conversation in SQLite:', {
        id: sessionId,
        title: conversationTitle,
        projectContext: projectContext.substring(0, 100) + '...'
      });
      
      this.aiChatDb.createConversation({
        id: sessionId,
        title: conversationTitle,
        project_context: projectContext,
        is_active: true
      });

      console.log('‚úÖ Successfully created conversation in SQLite:', sessionId);
    } catch (error) {
      console.error('‚ùå Failed to create conversation in SQLite:', error);
      console.error('‚ùå Conversation ID:', sessionId);
      console.error('‚ùå Error details:', error);
    }
  }

  /**
   * Save turn data to SQLite database
   */
  private saveTurnToSQLite(turn: ConversationTurn): void {
    if (!this.aiChatDb || !this.currentConversationId) {
      console.warn('‚ö†Ô∏è AI Chat database or conversation ID not available, skipping turn save');
      return;
    }

    try {
      // For now, let's save all messages from the conversation history
      // TODO: Optimize to only save new messages per turn
      const turnMessages = this.conversationHistory;

      console.log('üîß Saving turn to SQLite:', {
        conversationId: this.currentConversationId,
        turnNumber: turn.turnNumber,
        messageCount: turnMessages.length,
        totalHistoryLength: this.conversationHistory.length
      });

      // Convert and save messages
      const aiMessages = turnMessages.map(msg => conversationMessageToAIMessage(msg, this.currentConversationId!));
      
      // Remove duplicates based on content and timestamp (simple deduplication)
      const uniqueMessages = aiMessages.filter((msg, index, arr) => 
        arr.findIndex(m => m.content === msg.content && m.role === msg.role) === index
      );
      
      console.log('üîß Converted messages for SQLite:', aiMessages.map(m => ({
        id: m.id,
        role: m.role,
        contentLength: m.content.length,
        content: m.content.substring(0, 100) + (m.content.length > 100 ? '...' : ''),
        conversationId: m.conversation_id
      })));

      // Debug: Log the original conversation messages
      console.log('üîß Original conversation messages:', turnMessages.map(msg => ({
        role: msg.role,
        partsCount: msg.parts.length,
        parts: msg.parts.map(part => ({
          hasText: !!part.text,
          hasFunctionCall: !!part.functionCall,
          hasFunctionResponse: !!part.functionResponse,
          text: part.text?.substring(0, 50) || 'N/A'
        }))
      })));

      this.aiChatDb.addMessages(uniqueMessages);

      // Update conversation metadata
      this.aiChatDb.updateConversation(this.currentConversationId, {
        updated_at: new Date().toISOString()
      });

      console.log(`‚úÖ Successfully saved ${uniqueMessages.length} messages from turn ${turn.turnNumber} to SQLite`);
    } catch (error) {
      console.error('‚ùå Failed to save turn to SQLite:', error);
      console.error('‚ùå Conversation ID:', this.currentConversationId);
      console.error('‚ùå Turn number:', turn.turnNumber);
      console.error('‚ùå Error details:', error);
    }
  }

  /**
   * Generate a conversation title from the initial message
   */
  private generateConversationTitle(message: string): string {
    // Truncate and clean the message for use as title
    const maxLength = 50;
    const cleaned = message.replace(/\n/g, ' ').trim();
    return cleaned.length > maxLength 
      ? cleaned.substring(0, maxLength) + '...'
      : cleaned || 'AI Conversation';
  }

  /**
   * Cleanup method
   */
  unregisterHandlers(): void {
    ipcMain.removeHandler('ai-configure');
    ipcMain.removeHandler('ai-is-configured');
    ipcMain.removeHandler('ai-start-autonomous-conversation');
    ipcMain.removeHandler('ai-conversation-ready');
    ipcMain.removeHandler('ai-cancel-conversation');
    ipcMain.removeHandler('ai-get-conversation-state');
    ipcMain.removeHandler('ai-get-history');
    ipcMain.removeHandler('ai-clear-history');
    ipcMain.removeHandler('ai-get-models');
  }
}

// Export singleton instance
export const autonomousGeminiClient = new AutonomousGeminiClient();
